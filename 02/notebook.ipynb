{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you need python 3.7 to have use datetime.datetime.fromisoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import itertools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, limit=None):\n",
    "    with open(path, encoding='utf8') as file:\n",
    "        reader = csv.reader(file, delimiter=',')\n",
    "        # get header\n",
    "        header = next(reader)\n",
    "        data = [[value for value in row]\n",
    "                for row in itertools.islice(reader, limit)]\n",
    "    return np.asarray(header), np.asarray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header, data = load_data(\"data/training.csv\", limit=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/ Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.1. Remove features with mostly missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sample(header, data, n=0):\n",
    "    for i, (feature, value) in enumerate(zip(header, data[n])):\n",
    "        print(\"({:^2d}) {:30} : {}\".format(i, feature, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_feature(header, data, max_feature=5):\n",
    "    for n_feature, feature in enumerate(data.T):\n",
    "        values, counts = np.unique(feature, return_counts=True)\n",
    "        counts_values = sorted(zip(counts, values), reverse=True)\n",
    "        print(\"-\" * 50)\n",
    "        print(\"({:02d}) {} ({})\".format(n_feature, header[n_feature],\n",
    "                                        len(values)))\n",
    "        print(\"-\" * 50)\n",
    "        for i, (v, c) in enumerate(counts_values):\n",
    "            if i > max_feature:\n",
    "                break\n",
    "            print(\"{:10} : {:10} ({:5.1%})\".format(c, v, v / data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_feature(header, data, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * We can remove the feature without values in over 50% of samples. \n",
    "\n",
    " * We decide to keep Weather as it is discrete and we can easily replace it with a one-hot vector. \n",
    "\n",
    " * We also need to remove Withdrawals that is not available in test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_feature(header, data, feature_name):\n",
    "    assert feature_name in header, \"Index of {} does not exist\".format(\n",
    "        feature_name)\n",
    "\n",
    "    index = np.where(header == feature_name)\n",
    "    return np.delete(header, index), np.delete(data, index, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header, data = delete_feature(header, data, \"Visility indicator\")\n",
    "header, data = delete_feature(header, data, \"hmdx\")\n",
    "header, data = delete_feature(header, data, \"Wind Chill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.2 Convert Date to Year, Month, Day, Hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the date we can extract several informations : the Year, the Month, the day, and the hour.\n",
    "\n",
    "From this, we can also deduce a useful information : the day of the week (if it's Monday, Tuesday, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(header, data):\n",
    "    assert \"Date/Hour\" in header, \"Index of Date/Hour does not exist\"\n",
    "\n",
    "    new_data = []\n",
    "    index = np.where(header == \"Date/Hour\")\n",
    "\n",
    "    for i, d in enumerate(data):\n",
    "        dt = datetime.fromisoformat(d[index][0])\n",
    "        new_data.append(\n",
    "            np.concatenate(\n",
    "                (np.delete(d,\n",
    "                           index), [dt.year, dt.month, dt.day,\n",
    "                                    dt.hour], np.eye(7)[dt.date().weekday()])))\n",
    "\n",
    "    date_header = [\n",
    "        \"Year\", \"Month\", \"Day\", \"Hour\", \"Monday\", \"Tuesday\", \"Wednesday\",\n",
    "        \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"\n",
    "    ]\n",
    "    new_header = np.concatenate((np.delete(header, index), date_header))\n",
    "\n",
    "    return np.asarray(new_header), np.asarray(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header, data = convert_date(header, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2.1 One Hot encoding for Year and Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_one_hot(header, data, feature_name):\n",
    "    assert feature_name in header, \"Index of {} does not exist\".format(\n",
    "        feature_name)\n",
    "\n",
    "    index = np.where(header == feature_name)\n",
    "    \n",
    "    new_header, new_data = [], []\n",
    "    \n",
    "    mapping, enc = np.unique(data[:, index], return_inverse=True)\n",
    "    \n",
    "    add_header = [feature_name + \" \" + str(m) for m in mapping]\n",
    "    \n",
    "    new_header = np.concatenate((np.delete(header, index), add_header))\n",
    "\n",
    "    for i, (d, e) in enumerate(zip(data, enc)):\n",
    "        v = np.eye(mapping.shape[0])[e]\n",
    "        new_data.append(np.concatenate((np.delete(d, index), v)))\n",
    "\n",
    "    return np.asarray(new_header), np.asarray(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header, data = convert_one_hot(header, data, \"Year\")\n",
    "header, data = convert_one_hot(header, data, \"Month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.3 Convert Weather to binary vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_weather(header, data, weather):\n",
    "    assert \"Weather\" in header, \"Index of Weather does not exist\"\n",
    "\n",
    "    new_data = []\n",
    "    N = len(weather)\n",
    "    index = np.where(header == \"Weather\")\n",
    "\n",
    "    for i, d in enumerate(data):\n",
    "        new_weather = [\n",
    "            1 if any([w == v for v in d[index][0].split(\",\")]) else 0\n",
    "            for w in weather\n",
    "        ]\n",
    "        new_data.append(np.concatenate((np.delete(d, index), new_weather)))\n",
    "\n",
    "    new_header = np.concatenate((np.delete(header, index), weather))\n",
    "\n",
    "    return np.asarray(new_header), np.asarray(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = [\n",
    "    'Orages', 'Brouillard', 'Bruine', 'Généralement dégagé',\n",
    "    'Généralement nuageux', 'Pluie', 'Pluie modérée', 'Pluie forte', 'Dégagé',\n",
    "    'Nuageux', 'Neige'\n",
    "]\n",
    "\n",
    "header, data = convert_weather(header, data, weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.4. Convert feature type from string to float (remove samples with missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples with at least one missing value\n",
    "missing = [d for d in data if \"\" in d]\n",
    "print(len(missing))\n",
    "\n",
    "# number of class 1 with missing value\n",
    "index = np.where(header == \"Volume\")\n",
    "print(sum([\"1\" in d[index] for d in missing]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove the samples with missing values as only one hundred have label 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_type(data):\n",
    "    return np.asarray([[float(v.replace(\",\", \".\")) for v in d] for d in data\n",
    "                       if \"\" not in d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = convert_type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.5. Normalization of continuous data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concerned features are : Temperature, Drew point, Relativite humidity, wind direction, Wind speed, and Pressure at the station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization_feature(header, data, feature_name):\n",
    "    assert feature_name in header, \"Index of {} does not exist\".format(\n",
    "        feature_name)\n",
    "    index = np.where(header == feature_name)\n",
    "    data[:, index] = (data[:, index] - np.mean(data[:, index])) / np.std(\n",
    "        data[:, index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_feature(header, data, \"Temperature (°C)\")\n",
    "normalization_feature(header, data, \"Drew point (°C)\")\n",
    "normalization_feature(header, data, \"Relativite humidity (%)\")\n",
    "normalization_feature(header, data, \"wind direction (10s deg)\")\n",
    "normalization_feature(header, data, \"Wind speed (km/h)\")\n",
    "normalization_feature(header, data, \"Pressure at the station (kPa)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.6. Get x, y (withdrawals) and label (volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(header, data):\n",
    "    y_index = np.where(header == \"Withdrawals\")\n",
    "    l_index = np.where(header == \"Volume\")\n",
    "\n",
    "    y = data[:, y_index].reshape(-1)\n",
    "    label = data[:, l_index].reshape(-1)\n",
    "    x = np.delete(data, (y_index, l_index), 1)\n",
    "\n",
    "    header = np.delete(header, (y_index, l_index))\n",
    "    \n",
    "    return header, x, y, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header, x, y, label = split(header, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II/ Data analysis & visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.1. Distribution of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature(header, x, feature_name):\n",
    "    assert feature_name in header, \"Index of {} does not exist\".format(\n",
    "        feature_name)\n",
    "    index = np.where(header == feature_name)\n",
    "\n",
    "    plt.figure(figsize=(6, 4), dpi=300)\n",
    "    sns.distplot(x[:, index])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature(header, x, \"Temperature (°C)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.2. Correlation of features and output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2.1. Correlation matrix of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def corr_matrix(header, x):\n",
    "    mask = np.zeros((x.shape[1], x.shape[1]), dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "    plt.figure(figsize=(14, 12), dpi=300)\n",
    "    sns.heatmap(np.corrcoef(x.T),\n",
    "                mask=mask,\n",
    "                center=0,\n",
    "                cmap=cmap,\n",
    "                square=True,\n",
    "                linewidths=.5,\n",
    "                cbar_kws={\"shrink\": .5},\n",
    "                xticklabels=header,\n",
    "                yticklabels=header)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2.2. Correlation between each features with the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_output_corr(header, x, y, limit=None):\n",
    "    coeff = [np.corrcoef(feature, y)[0][1] for feature in x.T]\n",
    "    abs_coeff = list(map(abs, coeff))\n",
    "\n",
    "    for _, coeff, name in itertools.islice(\n",
    "            sorted(zip(abs_coeff, coeff, header), reverse=True), limit):\n",
    "        print(\"{:30} : {:6.3f}\".format(name, coeff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_output_corr(header, x, y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_output_corr(header, x, label, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(path=\"data/training.csv\",\n",
    "             limit=None,\n",
    "             delete_features=[\"Visility indicator\", \"hmdx\", \"Wind Chill\"],\n",
    "             cvrt_date=True,\n",
    "             weather=[\n",
    "                 \"Orages\", \"Brouillard\", \"Bruine\", \"Généralement dégagé\",\n",
    "                 \"Généralement nuageux\", \"Pluie\", \"Pluie modérée\",\n",
    "                 \"Pluie forte\", \"Dégagé\", \"Nuageux\", \"Neige\"\n",
    "             ],\n",
    "             one_hot_features=[\"Year\", \"Month\"]):\n",
    "    \"\"\"\n",
    "    path :           (STRING) path of the file to load.\n",
    "    limit:           (INT) limit the number of example to load.\n",
    "    delete_features: (LIST) feature names to remove.\n",
    "    cvrt_date:       (BOOLEAN) convert the data\n",
    "    weather:         (LIST) weather to consider. All other will be dropped.\n",
    "    one_hot_features (LIST) feature names to convert in one-hot vector\n",
    "    \"\"\"\n",
    "    header, data = load_data(path, limit)\n",
    "\n",
    "    for f in delete_features:\n",
    "        header, data = delete_feature(header, data, f)\n",
    "\n",
    "    if cvrt_date:\n",
    "        header, data = convert_date(header, data)\n",
    "\n",
    "    for f in one_hot_features:\n",
    "        header, data = convert_one_hot(header, data, f)\n",
    "\n",
    "    if weather:\n",
    "        header, data = convert_weather(header, data, weather)\n",
    "\n",
    "    data = convert_type(data)\n",
    "\n",
    "    return split(header, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header, x, y, label = pipeline(limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(x.shape[0] * 0.8)\n",
    "x_train, x_test = x[:split], x[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "label_train, label_test = label[:split], label[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(proba, y_true, step=0.01, plot=False):\n",
    "    f1 = []\n",
    "\n",
    "    for threshold in np.arange(0, 1, step):\n",
    "        y_pred = [int(y > threshold) for y in proba]\n",
    "        f1.append(f1_score(y_true, y_pred) if 1 in y_pred else 0)\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(6, 4), dpi=300)\n",
    "        plt.plot(np.arange(0, 1, step), f1)\n",
    "        plt.xlabel('Threshold')\n",
    "        plt.ylabel('F1-score')\n",
    "        plt.show()\n",
    "\n",
    "    return max(f1), step * np.argmax(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=9999, class_weight={0: 1, 1: 6})\n",
    "model = model.fit(x_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict_proba(x_test)\n",
    "proba = list(zip(*prediction))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_f1(proba, label_test, plot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
