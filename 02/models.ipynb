{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you need python 3.7 to have use datetime.datetime.fromisoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import numpy as np\n",
    "from functions import split\n",
    "from functions import pipeline\n",
    "from functions import load_data\n",
    "from functions import compute_f1\n",
    "from functions import corr_matrix\n",
    "from functions import plot_feature\n",
    "from functions import print_sample\n",
    "from functions import convert_date\n",
    "from functions import convert_type\n",
    "from functions import print_feature\n",
    "from functions import remove_missing\n",
    "from functions import delete_feature\n",
    "from functions import sort_by_station\n",
    "from functions import convert_one_hot\n",
    "from functions import convert_weather\n",
    "from functions import sort_by_duration\n",
    "from functions import feature_output_corr\n",
    "from functions import normalization_feature\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Preprocessing :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* path : (STRING) path of the file to load.\n",
    "* limit : (INT) limit the number of example to load.\n",
    "* delete_features : (LIST) feature names to remove.\n",
    "* cvrt_date : (BOOLEAN) convert the data\n",
    "* weather : (LIST) weather to consider. All other will be dropped.\n",
    "* one_hot_features : (LIST) feature names to convert in one-hot vector.\n",
    "* norm_features : (LIST) feature names to normalize in one-hot vector\n",
    "* missing_features (LIST) feature which missing values are to replace \n",
    "* missing_values   (LIST) value with which to replace the missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded (4.9s)\n",
      "Visility indicator deleted (5.7s)\n",
      "hmdx deleted (5.0s)\n",
      "Wind Chill deleted (6.4s)\n",
      "Date splited in Year/Month/Day/Hour/Weekday (7.5s)\n",
      "Weekday converted in one-hot vector (14.5s)\n",
      "Weather converted (21.6s)\n",
      "Replace missing values (0.2s)\n",
      "Remove samples with missing values (0.7s)\n",
      "Data converted to float (11.4s)\n",
      "Temperature (째C) normalized (14.2s)\n",
      "Drew point (째C) normalized (14.8s)\n",
      "Relativite humidity (%) normalized (14.3s)\n",
      "wind direction (10s deg) normalized (14.1s)\n",
      "Wind speed (km/h) normalized (13.4s)\n",
      "Pressure at the station (kPa) normalized (16.3s)\n",
      "Visibility (km) normalized (15.4s)\n",
      "Sort data according to station code (0.7s)\n",
      "split data into x, y, and label (52.3s)\n"
     ]
    }
   ],
   "source": [
    "header, x, y, label = pipeline(path=\"data/training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "header, stations, x_stations, y_stations, label_stations = sort_by_station(header, x, y, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded (0.9s)\n",
      "Visility indicator deleted (1.8s)\n",
      "hmdx deleted (1.7s)\n",
      "Wind Chill deleted (2.9s)\n",
      "Date splited in Year/Month/Day/Hour/Weekday (2.0s)\n",
      "Weekday converted in one-hot vector (3.9s)\n",
      "Weather converted (4.0s)\n",
      "Replace missing values (0.0s)\n",
      "Remove samples with missing values (0.1s)\n",
      "Data converted to float (2.1s)\n",
      "Temperature (째C) normalized (5.1s)\n",
      "Drew point (째C) normalized (3.9s)\n",
      "Relativite humidity (%) normalized (3.8s)\n",
      "wind direction (10s deg) normalized (3.9s)\n",
      "Wind speed (km/h) normalized (3.7s)\n",
      "Pressure at the station (kPa) normalized (4.1s)\n",
      "Visibility (km) normalized (5.4s)\n",
      "Sort data according to station code (0.2s)\n"
     ]
    }
   ],
   "source": [
    "header_test, x_test = pipeline(path=\"data/test.csv\", test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "header, stations_test, x_test_stations  = sort_by_station(header_test, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(stations == stations_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model logistic par station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 Stations done\n",
      "Done!\n",
      "f1-score mean : 0.471134\n"
     ]
    }
   ],
   "source": [
    "yi = header_test.index(\"Year\")\n",
    "mi = header_test.index(\"Month\")\n",
    "di = header_test.index(\"Day\")\n",
    "hi = header_test.index(\"Hour\")\n",
    "si = header_test.index(\"Station Code\")\n",
    "\n",
    "f1mean = []\n",
    "\n",
    "with open(\"data/results.csv\", \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    writer.writerow([\"id\",\"volume\"])\n",
    "    \n",
    "    for i, s in enumerate(stations):\n",
    "        \n",
    "        # if empty (no recording for that station in test set)\n",
    "        if not x_test_stations[i]:\n",
    "            continue\n",
    "        \n",
    "        # sort by time\n",
    "        _x, _y, _label = sort_by_duration(header, x_stations[i], y_stations[i], label_stations[i])\n",
    "\n",
    "        #deleting outliers + Dealing with sqrt(y) instead of y\n",
    "#         non_out_ind = np.where(np.asarray(_y) < 50)\n",
    "#         _x = np.asarray(_x)[non_out_ind].tolist()\n",
    "#         _y = np.asarray(_y)[non_out_ind].tolist() \n",
    "#         _label = np.asarray(_label)[non_out_ind].tolist()\n",
    "        \n",
    "        # create validation set\n",
    "        split = int(0.8*len(_x))\n",
    "        x_train, x_valid = _x[:split],  _x[split:]\n",
    "        y_train, y_valid = _y[:split],  _y[split:]\n",
    "        label_train, label_valid = _label[:split],  _label[split:]\n",
    "        \n",
    "#         # Linear model\n",
    "#         model_linear = LinearRegression()\n",
    "#         model_linear = model_linear.fit(x_train, y_train)\n",
    "\n",
    "#         # evaluate model\n",
    "#         y_pred = model_linear.predict(x_valid)\n",
    "#         label_pred = [int(y > np.sqrt(8)) for y in y_pred]\n",
    "#         f1_score, threshold = compute_f1(label_pred, label_valid)\n",
    "#         f1mean.append(f1_score)\n",
    "        \n",
    "#         # prediction\n",
    "#         y_test = model_linear.predict(x_test_stations[i])\n",
    "        \n",
    "#         label_test = [int(y > np.sqrt(8)) for y in y_test]\n",
    "        \n",
    "        # regression logistic\n",
    "        weights = 1\n",
    "        best_f1_score, best_class_weight, best_threshold = 0, 0, 0\n",
    "        \n",
    "        for wi in range(10):\n",
    "            model = LogisticRegression(max_iter=9999, class_weight={0: 1, 1: wi}, solver=\"lbfgs\")\n",
    "            model.fit(x_train, label_train)\n",
    "\n",
    "            # evaluate model\n",
    "            proba_valid = list(zip(*model.predict_proba(x_valid)))[1]\n",
    "            f1_score, threshold = compute_f1(proba_valid, label_valid)\n",
    "            if f1_score > best_f1_score:\n",
    "                best_f1_score = f1_score\n",
    "                best_class_weight = wi\n",
    "                best_threshold = threshold\n",
    "\n",
    "        f1mean.append(best_f1_score)\n",
    "\n",
    "        model = LogisticRegression(max_iter=9999, class_weight={0: 1, 1: best_class_weight}, solver=\"lbfgs\")\n",
    "        model.fit(_x, _label)\n",
    "        \n",
    "        # prediction\n",
    "        proba_test = list(zip(*model.predict_proba(x_test_stations[i])))[1]\n",
    "        \n",
    "        label_test = [int(p > best_threshold) for p in proba_test]\n",
    "        \n",
    "        print (\"{}/{} Stations done\".format(i+1, len(stations)) , end=\"\\r\")\n",
    "        \n",
    "        # write prediction in file\n",
    "        for i, (e, p) in enumerate(zip(x_test_stations[i], label_test)):\n",
    "            d = \"2016-{:02d}-{:02d}_{:02d}:00_{:4d}\".format(int(e[mi]),int(e[di]),int(e[hi]),int(e[si]))\n",
    "            writer.writerow([d, str(bool(p))])\n",
    "print(\"\")\n",
    "print(\"Done!\")\n",
    "print(\"f1-score mean : {:4f}\".format(np.mean(f1mean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "header=np.asarray(header)\n",
    "x=np.asarray(x)\n",
    "y=np.asarray(y)\n",
    "label=np.asarray(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile at 0.99: 17.0\n",
      "10 Highest values: [179.0, 169.0, 169.0, 156.0, 156.0, 125.0, 123.0, 115.0, 109.0, 109.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Quantile at 0.99:\", np.quantile(y, 0.99))\n",
    "print(\"10 Highest values:\", sorted(y, reverse = True)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_out_ind = np.where(y < 50)\n",
    "x, y, label = x[non_out_ind], y[non_out_ind], label[non_out_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of the withdrawals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 450x300 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(6, 4), dpi=75)\n",
    "sns.distplot(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the tail of the distribution, we apply the square root function to to $y$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.sqrt(y)\n",
    "\n",
    "split = int(x.shape[0] * 0.8)\n",
    "x_train, x_valid = x[:split], x[split:]\n",
    "y_train, y_valid = y[:split], y[split:]\n",
    "label_train, label_valid = label[:split], label[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def fit_linear_reg(X,Y):\n",
    "    #Fit linear regression model and return RSS and R squared values\n",
    "    model_k = LinearRegression(fit_intercept = True)\n",
    "    model_k.fit(X,Y)\n",
    "    RSS = mean_squared_error(Y,model_k.predict(X)) * len(Y)\n",
    "    R_squared = model_k.score(X,Y)\n",
    "    return RSS, R_squared\n",
    "\n",
    "\n",
    "#Initialization variables\n",
    "Y = y_train\n",
    "X = x_train\n",
    "k = 25\n",
    "# k = len(header)\n",
    "\n",
    "remaining_features = [i for i in range(len(header))]\n",
    "features = []\n",
    "RSS_list, R_squared_list = [np.inf], [np.inf] #Due to 1 indexing of the loop...\n",
    "features_list = dict()\n",
    "\n",
    "for i in range(1,k+1):\n",
    "    best_RSS = np.inf\n",
    "    \n",
    "    for combo in itertools.combinations(remaining_features,1):\n",
    "\n",
    "            RSS = fit_linear_reg(X[:,list(combo) + features],Y)   #Store temp result \n",
    "\n",
    "            if RSS[0] < best_RSS:\n",
    "                best_RSS = RSS[0]\n",
    "                best_R_squared = RSS[1] \n",
    "                best_feature = combo[0]\n",
    "\n",
    "    #Updating variables for next loop\n",
    "    features.append(best_feature)\n",
    "    remaining_features.remove(best_feature)\n",
    "    \n",
    "    #Saving values for plotting\n",
    "    RSS_list.append(best_RSS)\n",
    "    R_squared_list.append(best_R_squared)\n",
    "    features_list[i] = features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward stepwise subset selection\n",
      "Number of features : 1\n",
      "Features : [0]\n",
      "RSS : 1337225.0\n",
      "R Squared : 0.1478101732415248\n",
      "\n",
      "Number of features : 2\n",
      "Features : [0, 2]\n",
      "RSS : 1197326.0\n",
      "R Squared : 0.2369656185666592\n",
      "\n",
      "Number of features : 3\n",
      "Features : [0, 2, 12]\n",
      "RSS : 1123123.0\n",
      "R Squared : 0.2842536583364178\n",
      "\n",
      "Number of features : 4\n",
      "Features : [0, 2, 12, 5]\n",
      "RSS : 1108891.0\n",
      "R Squared : 0.29332342711774484\n",
      "\n",
      "Number of features : 5\n",
      "Features : [0, 2, 12, 5, 8]\n",
      "RSS : 1102947.0\n",
      "R Squared : 0.29711162107018985\n",
      "\n",
      "Number of features : 6\n",
      "Features : [0, 2, 12, 5, 8, 19]\n",
      "RSS : 1098416.0\n",
      "R Squared : 0.29999913997376215\n",
      "\n",
      "Number of features : 7\n",
      "Features : [0, 2, 12, 5, 8, 19, 10]\n",
      "RSS : 1096273.0\n",
      "R Squared : 0.30136449094495454\n",
      "\n",
      "Number of features : 8\n",
      "Features : [0, 2, 12, 5, 8, 19, 10, 18]\n",
      "RSS : 1094619.0\n",
      "R Squared : 0.30241877443183995\n",
      "\n",
      "Number of features : 9\n",
      "Features : [0, 2, 12, 5, 8, 19, 10, 18, 7]\n",
      "RSS : 1093336.0\n",
      "R Squared : 0.30323658911782225\n",
      "\n",
      "Number of features : 10\n",
      "Features : [0, 2, 12, 5, 8, 19, 10, 18, 7, 4]\n",
      "RSS : 1092275.0\n",
      "R Squared : 0.30391258152830236\n",
      "\n",
      "Number of features : 11\n",
      "Features : [0, 2, 12, 5, 8, 19, 10, 18, 7, 4, 13]\n",
      "RSS : 1091328.0\n",
      "R Squared : 0.3045159475469328\n",
      "\n",
      "Number of features : 12\n",
      "Features : [0, 2, 12, 5, 8, 19, 10, 18, 7, 4, 13, 1]\n",
      "RSS : 1090546.0\n",
      "R Squared : 0.30501458578918883\n",
      "\n",
      "Number of features : 13\n",
      "Features : [0, 2, 12, 5, 8, 19, 10, 18, 7, 4, 13, 1, 22]\n",
      "RSS : 1089789.0\n",
      "R Squared : 0.30549651581602033\n",
      "\n",
      "Number of features : 14\n",
      "Features : [0, 2, 12, 5, 8, 19, 10, 18, 7, 4, 13, 1, 22, 28]\n",
      "RSS : 1089127.0\n",
      "R Squared : 0.3059183540323822\n",
      "\n",
      "Number of features : 15\n",
      "Features : [0, 2, 12, 5, 8, 19, 10, 18, 7, 4, 13, 1, 22, 28, 23]\n",
      "RSS : 1088868.0\n",
      "R Squared : 0.3060835257935899\n",
      "\n",
      "Number of features : 16\n",
      "Features : [0, 2, 12, 5, 8, 19, 10, 18, 7, 4, 13, 1, 22, 28, 23, 21]\n",
      "RSS : 1088634.0\n",
      "R Squared : 0.3062326750082718\n",
      "\n",
      "Number of features : 17\n",
      "Features : [0, 2, 12, 5, 8, 19, 10, 18, 7, 4, 13, 1, 22, 28, 23, 21, 3]\n",
      "RSS : 1088414.0\n",
      "R Squared : 0.3063732228110121\n",
      "\n",
      "Number of features : 18\n",
      "Features : [0, 2, 12, 5, 8, 19, 10, 18, 7, 4, 13, 1, 22, 28, 23, 21, 3, 14]\n",
      "RSS : 1088193.0\n",
      "R Squared : 0.3065137759060218\n",
      "\n",
      "Number of features : 19\n",
      "Features : [0, 2, 12, 5, 8, 19, 10, 18, 7, 4, 13, 1, 22, 28, 23, 21, 3, 14, 24]\n",
      "RSS : 1088027.0\n",
      "R Squared : 0.30661985566170114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,len(features_list)):\n",
    "    features_list[i] = [f for f in features_list[i] if header[f] in header_test]\n",
    "\n",
    "print('Forward stepwise subset selection')\n",
    "for i in range(1,20):\n",
    "    print('Number of features :', len(features_list[i]))\n",
    "    print('Features :', features_list[i])\n",
    "    print('RSS :', round(RSS_list[i]))\n",
    "    print('R Squared :', R_squared_list[i])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features that we choose to keep :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_keep = features_list[10]\n",
    "\n",
    "x_train = x_train[:, features_keep]\n",
    "x_valid = x_valid[:, features_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression on Withdrawals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  -0.4797704769167009\n",
      "Mean squared error: 1.58\n",
      "Variance score: -0.48\n"
     ]
    }
   ],
   "source": [
    "model_linear = LinearRegression()\n",
    "model_linear = model_linear.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model_linear.predict(x_valid)\n",
    "\n",
    "# The coefficients\n",
    "print('Score: ', model_linear.score(x_valid, y_valid))\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_valid, y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression between Withdrawals and Volume:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9177681925699179\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_logit = LogisticRegression(max_iter=9999, class_weight={0: 1, 1: 6})\n",
    "model_logit = model_logit.fit(y_train.reshape(-1,1), label_train)\n",
    "\n",
    "print(model_logit.score(y_valid.reshape(-1,1), label_valid))\n",
    "print(model_logit.score(model_linear.predict(x_valid).reshape(-1,1), label_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of the result file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-d4075dfb132e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m features_keep_test = [np.where(i == header_test)[0][0] \n\u001b[1;32m----> 2\u001b[1;33m                       for i in header[features_keep]]\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mx_test_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures_keep_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-d4075dfb132e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m features_keep_test = [np.where(i == header_test)[0][0] \n\u001b[1;32m----> 2\u001b[1;33m                       for i in header[features_keep]]\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mx_test_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures_keep_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "features_keep_test = [np.where(i == header_test)[0][0] \n",
    "                      for i in header[features_keep]]\n",
    "x_test_f = x_test[:,features_keep_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred = model_logit.predict(model_linear.predict(x_test_f).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yi = np.where(header_test == \"Year\")\n",
    "mi = np.where(header_test == \"Month\")\n",
    "di = np.where(header_test == \"Day\")\n",
    "hi = np.where(header_test == \"Hour\")\n",
    "si = np.where(header_test == \"Station Code\")\n",
    "\n",
    "results = [[\"id\",\"volume\"]]\n",
    "\n",
    "for index,element in enumerate(x_test):\n",
    "    string_element = \"2016-{:02d}-{:02d}_{:02d}:00_{:4d}\".format(int(element[mi]),\n",
    "                                                                 int(element[di]),\n",
    "                                                                 int(element[hi]),\n",
    "                                                                 int(element[si]))\n",
    "    results.append([string_element, str(bool(label_pred[index]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(model_logit.predict(model_linear.predict(x_valid).reshape(-1,1))))\n",
    "print(sum(model_logit.predict(model_linear.predict(x_test_f).reshape(-1,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "\n",
    "with open(\"data/results.csv\", \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    writer.writerows(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
